{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4WMHba48hhPr",
    "outputId": "695050c4-9987-42fb-a4ff-9a14dcff19b9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import h5py\n",
    "# from google.colab import drive\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import argparse\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h62qituRyUvS",
    "outputId": "22cdd60a-6901-43b6-92fc-a0e935bae60e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "xEjVqnIvAyS3"
   },
   "outputs": [],
   "source": [
    "classes = ['ceiling','floor','wall','beam','column','window','door','table','chair','sofa','bookcase','board','clutter']\n",
    "class2label = {cls: i for i,cls in enumerate(classes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "C5n5VeZrA2MJ"
   },
   "outputs": [],
   "source": [
    "def getDataFiles(list_filename):\n",
    "    return [line.rstrip() for line in open(list_filename)]\n",
    "\n",
    "def load_h5(h5_filename):\n",
    "    f = h5py.File(h5_filename)\n",
    "    data = f['data'][:]\n",
    "    label = f['label'][:]\n",
    "    return (data, label)\n",
    "\n",
    "def loadDataFile(filename):\n",
    "    # print(filename)\n",
    "    return load_h5('./' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Hrvu2NWwA41d"
   },
   "outputs": [],
   "source": [
    "def recognize_all_data(test_area = 5):\n",
    "    ALL_FILES = getDataFiles('./indoor3d_sem_seg_hdf5_data/all_files.txt')\n",
    "    room_filelist = [line.rstrip() for line in open('./indoor3d_sem_seg_hdf5_data/room_filelist.txt')]\n",
    "    data_batch_list = []\n",
    "    label_batch_list = []\n",
    "    for h5_filename in ALL_FILES:\n",
    "        data_batch, label_batch = loadDataFile(h5_filename)\n",
    "        data_batch_list.append(data_batch)\n",
    "        label_batch_list.append(label_batch)\n",
    "    data_batches = np.concatenate(data_batch_list, 0)\n",
    "    label_batches = np.concatenate(label_batch_list, 0)\n",
    "\n",
    "    test_area = 'Area_' + str(test_area)\n",
    "    train_idxs = []\n",
    "    test_idxs = []\n",
    "    for i, room_name in enumerate(room_filelist):\n",
    "        if test_area in room_name:\n",
    "            test_idxs.append(i)\n",
    "        else:\n",
    "            train_idxs.append(i)\n",
    "\n",
    "    train_data = data_batches[train_idxs, ...]\n",
    "    train_label = label_batches[train_idxs]\n",
    "    test_data = data_batches[test_idxs, ...]\n",
    "    test_label = label_batches[test_idxs]\n",
    "    print('train_data',train_data.shape,'train_label' ,train_label.shape)\n",
    "    print('test_data',test_data.shape,'test_label', test_label.shape)\n",
    "    return train_data,train_label,test_data,test_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "7BQ_xJWtBCF1"
   },
   "outputs": [],
   "source": [
    "class S3DISDataLoader(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.labels[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "do-JsdRKBJZn",
    "outputId": "226c2764-b5c8-4ebd-a45e-d032fbd38e22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data (16733, 4096, 9) train_label (16733, 4096)\n",
      "test_data (6852, 4096, 9) test_label (6852, 4096)\n"
     ]
    }
   ],
   "source": [
    "train_data, train_label, test_data, test_label = recognize_all_data(test_area = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PCA1LNhNDQqw",
    "outputId": "de9a382e-7563-494b-ad2e-cdb086f9170b"
   },
   "outputs": [],
   "source": [
    "dataset = S3DISDataLoader(train_data,train_label)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=24,\n",
    "                                             shuffle=True, num_workers=int(4))\n",
    "test_dataset = S3DISDataLoader(test_data,test_label)\n",
    "testdataloader = torch.utils.data.DataLoader(test_dataset, batch_size=8,\n",
    "                                                 shuffle=True, num_workers=int(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "hqCxTCF8DzEM"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from time import time\n",
    "\n",
    "def timeit(tag, t):\n",
    "    print(\"{}: {}s\".format(tag, time() - t))\n",
    "    return time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "HbhOKzjyEjKv"
   },
   "outputs": [],
   "source": [
    "def square_distance(src, dst):\n",
    "    \"\"\"\n",
    "    Calculate Euclid distance between each two points.\n",
    "\n",
    "    src^T * dst = xn * xm + yn * ym + zn * zmï¼›\n",
    "    sum(src^2, dim=-1) = xn*xn + yn*yn + zn*zn;\n",
    "    sum(dst^2, dim=-1) = xm*xm + ym*ym + zm*zm;\n",
    "    dist = (xn - xm)^2 + (yn - ym)^2 + (zn - zm)^2\n",
    "         = sum(src**2,dim=-1)+sum(dst**2,dim=-1)-2*src^T*dst\n",
    "\n",
    "    Input:\n",
    "        src: source points, [B, N, C]\n",
    "        dst: target points, [B, M, C]\n",
    "    Output:\n",
    "        dist: per-point square distance, [B, N, M]\n",
    "    \"\"\"\n",
    "    B, N, _ = src.shape\n",
    "    _, M, _ = dst.shape\n",
    "    dist = -2 * torch.matmul(src, dst.permute(0, 2, 1))\n",
    "    dist += torch.sum(src ** 2, -1).view(B, N, 1)\n",
    "    dist += torch.sum(dst ** 2, -1).view(B, 1, M)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "KVibk43bHuai"
   },
   "outputs": [],
   "source": [
    "def index_points(points, idx):\n",
    "    \"\"\"\n",
    "\n",
    "    Input:\n",
    "        points: input points data, [B, N, C]\n",
    "        idx: sample index data, [B, S]\n",
    "    Return:\n",
    "        new_points:, indexed points data, [B, S, C]\n",
    "    \"\"\"\n",
    "    device = points.device\n",
    "    B = points.shape[0]\n",
    "    view_shape = list(idx.shape)\n",
    "    view_shape[1:] = [1] * (len(view_shape) - 1)\n",
    "    repeat_shape = list(idx.shape)\n",
    "    repeat_shape[0] = 1\n",
    "    batch_indices = torch.arange(B, dtype=torch.long).to(device).view(view_shape).repeat(repeat_shape)\n",
    "    new_points = points[batch_indices, idx, :]\n",
    "    return new_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "rBU1GS33EqmH"
   },
   "outputs": [],
   "source": [
    "def farthest_point_sample(xyz, npoint):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        xyz: pointcloud data, [B, N, C]\n",
    "        npoint: number of samples\n",
    "    Return:\n",
    "        centroids: sampled pointcloud index, [B, npoint]\n",
    "    \"\"\"\n",
    "    device = xyz.device\n",
    "    B, N, C = xyz.shape\n",
    "    centroids = torch.zeros(B, npoint, dtype=torch.long).to(device)\n",
    "    distance = torch.ones(B, N).to(device) * 1e10\n",
    "    farthest = torch.randint(0, N, (B,), dtype=torch.long).to(device)\n",
    "    batch_indices = torch.arange(B, dtype=torch.long).to(device)\n",
    "    for i in range(npoint):\n",
    "        centroids[:, i] = farthest\n",
    "        centroid = xyz[batch_indices, farthest, :].view(B, 1, 3)\n",
    "        dist = torch.sum((xyz - centroid) ** 2, -1)\n",
    "        mask = dist < distance\n",
    "        distance[mask] = dist[mask]\n",
    "        farthest = torch.max(distance, -1)[1]\n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "yeh9GX1lEt-J"
   },
   "outputs": [],
   "source": [
    "def query_ball_point(radius, nsample, xyz, new_xyz):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        radius: local region radius\n",
    "        nsample: max sample number in local region\n",
    "        xyz: all points, [B, N, C]\n",
    "        new_xyz: query points, [B, S, C]\n",
    "    Return:\n",
    "        group_idx: grouped points index, [B, S, nsample]\n",
    "    \"\"\"\n",
    "    device = xyz.device\n",
    "    B, N, C = xyz.shape\n",
    "    _, S, _ = new_xyz.shape\n",
    "    group_idx = torch.arange(N, dtype=torch.long).to(device).view(1, 1, N).repeat([B, S, 1])\n",
    "    sqrdists = square_distance(new_xyz, xyz)\n",
    "    group_idx[sqrdists > radius ** 2] = N\n",
    "    group_idx = group_idx.sort(dim=-1)[0][:, :, :nsample]\n",
    "    group_first = group_idx[:, :, 0].view(B, S, 1).repeat([1, 1, nsample])\n",
    "    mask = group_idx == N\n",
    "    group_idx[mask] = group_first[mask]\n",
    "    return group_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "7XoD1dmFEw7s"
   },
   "outputs": [],
   "source": [
    "def sample_and_group(npoint, radius, nsample, xyz, points, returnfps=False):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        npoint:\n",
    "        radius:\n",
    "        nsample:\n",
    "        xyz: input points position data, [B, N, C]\n",
    "        points: input points data, [B, N, D]\n",
    "    Return:\n",
    "        new_xyz: sampled points position data, [B, 1, C]\n",
    "        new_points: sampled points data, [B, 1, N, C+D]\n",
    "    \"\"\"\n",
    "    B, N, C = xyz.shape\n",
    "    S = npoint\n",
    "    fps_idx = farthest_point_sample(xyz, npoint) # [B, npoint, C]\n",
    "    new_xyz = index_points(xyz, fps_idx)\n",
    "    idx = query_ball_point(radius, nsample, xyz, new_xyz)\n",
    "    grouped_xyz = index_points(xyz, idx) # [B, npoint, nsample, C]\n",
    "    grouped_xyz_norm = grouped_xyz - new_xyz.view(B, S, 1, C)\n",
    "    if points is not None:\n",
    "        grouped_points = index_points(points, idx)\n",
    "        fps_points = index_points(points, fps_idx)\n",
    "        fps_points = torch.cat([new_xyz, fps_points], dim=-1)\n",
    "        new_points = torch.cat([grouped_xyz_norm, grouped_points], dim=-1) # [B, npoint, nsample, C+D]\n",
    "    else:\n",
    "        new_points = grouped_xyz_norm\n",
    "        fps_points = new_xyz\n",
    "    if returnfps:\n",
    "        return new_xyz, new_points, grouped_xyz, fps_points\n",
    "    else:\n",
    "        return new_xyz, new_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ABmAoV-bE-ia"
   },
   "outputs": [],
   "source": [
    "def sample_and_group_all(xyz, points):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        xyz: input points position data, [B, N, C]\n",
    "        points: input points data, [B, N, D]\n",
    "    Return:\n",
    "        new_xyz: sampled points position data, [B, 1, C]\n",
    "        new_points: sampled points data, [B, 1, N, C+D]\n",
    "    \"\"\"\n",
    "    device = xyz.device\n",
    "    B, N, C = xyz.shape\n",
    "    new_xyz = torch.zeros(B, 1, C).to(device)\n",
    "    grouped_xyz = xyz.view(B, 1, N, C)\n",
    "    if points is not None:\n",
    "        new_points = torch.cat([grouped_xyz, points.view(B, 1, N, -1)], dim=-1)\n",
    "    else:\n",
    "        new_points = grouped_xyz\n",
    "    return new_xyz, new_points\n",
    "\n",
    "class GraphAttention(nn.Module):\n",
    "    def __init__(self,all_channel,feature_dim,dropout,alpha):\n",
    "        super(GraphAttention, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.a = nn.Parameter(torch.zeros(size=(all_channel, feature_dim)))\n",
    "        nn.init.xavier_uniform_(self.a.data, gain=1.414)\n",
    "        self.dropout = dropout\n",
    "        self.leakyrelu = nn.LeakyReLU(self.alpha)\n",
    "\n",
    "    def forward(self, center_xyz, center_feature, grouped_xyz, grouped_feature):\n",
    "        '''\n",
    "        Input:\n",
    "            center_xyz: sampled points position data [B, npoint, C]\n",
    "            center_feature: centered point feature [B, npoint, D]\n",
    "            grouped_xyz: group xyz data [B, npoint, nsample, C]\n",
    "            grouped_feature: sampled points feature [B, npoint, nsample, D]\n",
    "        Return:\n",
    "            graph_pooling: results of graph pooling [B, npoint, D]\n",
    "        '''\n",
    "        B, npoint, C = center_xyz.size()\n",
    "        _, _, nsample, D = grouped_feature.size()\n",
    "        delta_p = center_xyz.view(B, npoint, 1, C).expand(B, npoint, nsample, C) - grouped_xyz # [B, npoint, nsample, C]\n",
    "        delta_h = center_feature.view(B, npoint, 1, D).expand(B, npoint, nsample, D) - grouped_feature # [B, npoint, nsample, D]\n",
    "        delta_p_concat_h = torch.cat([delta_p,delta_h],dim = -1) # [B, npoint, nsample, C+D]\n",
    "        e = self.leakyrelu(torch.matmul(delta_p_concat_h, self.a)) # [B, npoint, nsample,D]\n",
    "        attention = F.softmax(e, dim=2) # [B, npoint, nsample,D]\n",
    "        attention = F.dropout(attention, self.dropout, training=self.training)\n",
    "        graph_pooling = torch.sum(torch.mul(attention, grouped_feature),dim = 2) # [B, npoint, D]\n",
    "        return graph_pooling\n",
    "\n",
    "\n",
    "class GraphAttentionConvLayer(nn.Module):\n",
    "    def __init__(self, npoint, radius, nsample, in_channel, mlp, group_all,droupout=0.6,alpha=0.2):\n",
    "        super(GraphAttentionConvLayer, self).__init__()\n",
    "        self.npoint = npoint\n",
    "        self.radius = radius\n",
    "        self.nsample = nsample\n",
    "        self.mlp_convs = nn.ModuleList()\n",
    "        self.mlp_bns = nn.ModuleList()\n",
    "        self.droupout = droupout\n",
    "        self.alpha = alpha\n",
    "        last_channel = in_channel\n",
    "        for out_channel in mlp:\n",
    "            self.mlp_convs.append(nn.Conv2d(last_channel, out_channel, 1))\n",
    "            self.mlp_bns.append(nn.BatchNorm2d(out_channel))\n",
    "            last_channel = out_channel\n",
    "        self.group_all = group_all\n",
    "        self.GAT = GraphAttention(3+last_channel,last_channel,self.droupout,self.alpha)\n",
    "\n",
    "    def forward(self, xyz, points):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            xyz: input points position data, [B, C, N]\n",
    "            points: input points data, [B, D, N]\n",
    "        Return:\n",
    "            new_xyz: sampled points position data, [B, C, S]\n",
    "            new_points_concat: sample points feature data, [B, D', S]\n",
    "        \"\"\"\n",
    "        xyz = xyz.permute(0, 2, 1)\n",
    "        if points is not None:\n",
    "            points = points.permute(0, 2, 1)\n",
    "\n",
    "        if self.group_all:\n",
    "            new_xyz, new_points = sample_and_group_all(xyz, points)\n",
    "        else:\n",
    "            new_xyz, new_points, grouped_xyz, fps_points = sample_and_group(self.npoint, self.radius, self.nsample, xyz, points, True)\n",
    "        # new_xyz: sampled points position data, [B, npoint, C]\n",
    "        # new_points: sampled points data, [B, npoint, nsample, C+D]\n",
    "        # fps_points: [B, npoint, C+D,1]\n",
    "        new_points = new_points.permute(0, 3, 2, 1) # [B, C+D, nsample,npoint]\n",
    "        fps_points = fps_points.unsqueeze(3).permute(0, 2, 3, 1) # [B, C+D, 1,npoint]\n",
    "        for i, conv in enumerate(self.mlp_convs):\n",
    "            bn = self.mlp_bns[i]\n",
    "            fps_points = F.relu(bn(conv(fps_points)))\n",
    "            new_points =  F.relu(bn(conv(new_points)))\n",
    "        # new_points: [B, F, nsample,npoint]\n",
    "        # fps_points: [B, F, 1,npoint]\n",
    "        new_points = self.GAT(center_xyz=new_xyz,\n",
    "                              center_feature=fps_points.squeeze().permute(0,2,1),\n",
    "                              grouped_xyz=grouped_xyz,\n",
    "                              grouped_feature=new_points.permute(0,3,2,1))\n",
    "        new_xyz = new_xyz.permute(0, 2, 1)\n",
    "        new_points = new_points.permute(0, 2, 1)\n",
    "        return new_xyz, new_points\n",
    "\n",
    "class PointNetFeaturePropagation(nn.Module):\n",
    "    def __init__(self, in_channel, mlp):\n",
    "        super(PointNetFeaturePropagation, self).__init__()\n",
    "        self.mlp_convs = nn.ModuleList()\n",
    "        self.mlp_bns = nn.ModuleList()\n",
    "        last_channel = in_channel\n",
    "        for out_channel in mlp:\n",
    "            self.mlp_convs.append(nn.Conv1d(last_channel, out_channel, 1))\n",
    "            self.mlp_bns.append(nn.BatchNorm1d(out_channel))\n",
    "            last_channel = out_channel\n",
    "\n",
    "    def forward(self, xyz1, xyz2, points1, points2):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            xyz1: input points position data, [B, C, N]\n",
    "            xyz2: sampled input points position data, [B, C, S]\n",
    "            points1: input points data, [B, D, N]\n",
    "            points2: input points data, [B, D, S]\n",
    "        Return:\n",
    "            new_points: upsampled points data, [B, D', N]\n",
    "        \"\"\"\n",
    "        xyz1 = xyz1.permute(0, 2, 1)\n",
    "        xyz2 = xyz2.permute(0, 2, 1)\n",
    "\n",
    "        points2 = points2.permute(0, 2, 1)\n",
    "        B, N, C = xyz1.shape\n",
    "        _, S, _ = xyz2.shape\n",
    "\n",
    "        if S == 1:\n",
    "            interpolated_points = points2.repeat(1, N, 1)\n",
    "        else:\n",
    "            dists = square_distance(xyz1, xyz2)\n",
    "            dists, idx = dists.sort(dim=-1)\n",
    "            dists, idx = dists[:, :, :3], idx[:, :, :3]  # [B, N, 3]\n",
    "            dists[dists < 1e-10] = 1e-10\n",
    "            weight = 1.0 / dists  # [B, N, 3]\n",
    "            weight = weight / torch.sum(weight, dim=-1).view(B, N, 1)  # [B, N, 3]\n",
    "            interpolated_points = torch.sum(index_points(points2, idx) * weight.view(B, N, 3, 1), dim=2)\n",
    "\n",
    "        if points1 is not None:\n",
    "            points1 = points1.permute(0, 2, 1)\n",
    "            new_points = torch.cat([points1, interpolated_points], dim=-1)\n",
    "        else:\n",
    "            new_points = interpolated_points\n",
    "\n",
    "        new_points = new_points.permute(0, 2, 1)\n",
    "        for i, conv in enumerate(self.mlp_convs):\n",
    "            bn = self.mlp_bns[i]\n",
    "            new_points =  F.relu(bn(conv(new_points)))\n",
    "        return new_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "7-ZQcRU3E-pw"
   },
   "outputs": [],
   "source": [
    "class GACNet(nn.Module):\n",
    "    def __init__(self, num_classes,droupout=0,alpha=0.2):\n",
    "        super(GACNet, self).__init__()\n",
    "        # GraphAttentionConvLayer: npoint, radius, nsample, in_channel, mlp, group_all,droupout,alpha\n",
    "        self.sa1 = GraphAttentionConvLayer(1024, 0.1, 32, 6 + 3, [32, 32, 64], False, droupout,alpha)\n",
    "        self.sa2 = GraphAttentionConvLayer(256, 0.2, 32, 64 + 3, [64, 64, 128], False, droupout,alpha)\n",
    "        self.sa3 = GraphAttentionConvLayer(64, 0.4, 32, 128 + 3, [128, 128, 256], False, droupout,alpha)\n",
    "        self.sa4 = GraphAttentionConvLayer(16, 0.8, 32, 256 + 3, [256, 256, 512], False, droupout,alpha)\n",
    "        # self.sa1 = GraphAttentionConvLayer(1024, 0.1, 32, 6 + 3, [32, 32], False, droupout,alpha)\n",
    "        # self.sa2 = GraphAttentionConvLayer(256, 0.2, 32, 32 + 3, [64, 64], False, droupout,alpha)\n",
    "        # self.sa3 = GraphAttentionConvLayer(64, 0.4, 32, 64 + 3, [128, 128], False, droupout,alpha)\n",
    "        # self.sa4 = GraphAttentionConvLayer(16, 0.8, 32, 128 + 3, [300, 300, 300, 300], False, droupout,alpha)\n",
    "        # PointNetFeaturePropagation: in_channel, mlp\n",
    "        # self.fp4 = PointNetFeaturePropagation(768, [256, 256])\n",
    "        # self.fp3 = PointNetFeaturePropagation(384, [256, 256])\n",
    "        # self.fp2 = PointNetFeaturePropagation(320, [256, 128])\n",
    "        # self.fp1 = PointNetFeaturePropagation(128, [128, 128, 128])\n",
    "        self.fp4 = PointNetFeaturePropagation(768, [128, 128])\n",
    "        self.fp3 = PointNetFeaturePropagation(256, [64, 64])\n",
    "        self.fp2 = PointNetFeaturePropagation(768, [32, 32])\n",
    "        self.fp1 = PointNetFeaturePropagation(768, [300, 300, 300, 300])\n",
    "\n",
    "        # self.conv1 = nn.Conv1d(128, 128, 1)\n",
    "        self.conv1 = nn.Conv1d(128, 128, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.drop1 = nn.Dropout(droupout)\n",
    "        self.conv2 = nn.Conv1d(128, num_classes, 1)\n",
    "\n",
    "    def forward(self, xyz, point):\n",
    "        l1_xyz, l1_points = self.sa1(xyz, point)\n",
    "        l2_xyz, l2_points = self.sa2(l1_xyz, l1_points)\n",
    "        l3_xyz, l3_points = self.sa3(l2_xyz, l2_points)\n",
    "        l4_xyz, l4_points = self.sa4(l3_xyz, l3_points)\n",
    "        \n",
    "        l3_points = self.fp4(l3_xyz, l4_xyz, l3_points, l4_points)\n",
    "        l2_points = self.fp3(l2_xyz, l3_xyz, l2_points, l3_points)\n",
    "        # print(l2_points.size())\n",
    "        # l1_points = self.fp2(l1_xyz, l2_xyz, l1_points, l2_points)\n",
    "        # l0_points = self.fp1(xyz, l1_xyz, None, l1_points)\n",
    "        # print(l0_points.size())\n",
    "\n",
    "        x = self.drop1(F.relu(self.bn1(self.conv1(l0_points))))\n",
    "        x = self.conv2(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "bha7YpLQFEz7"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "num_classes = 13\n",
    "blue = lambda x: '\\033[94m' + x + '\\033[0m'\n",
    "model = GACNet(num_classes,0,0.2)\n",
    "init_epoch = 0\n",
    "\n",
    "def adjust_learning_rate(optimizer, step):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 30 every 20000 steps\"\"\"\n",
    "    lr = 0.01 * (0.3 ** (step // 20000))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=0.01,\n",
    "            betas=(0.9, 0.999),\n",
    "            eps=1e-08,\n",
    "            weight_decay=1e-4)\n",
    "\n",
    "# model.cuda()\n",
    "\n",
    "history = defaultdict(lambda: list())\n",
    "best_acc = 0\n",
    "best_meaniou = 0\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cellView": "form",
    "id": "9598FuJENB2S"
   },
   "outputs": [],
   "source": [
    "# *_*coding:utf-8 *_*\n",
    "#@title Utils here\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "def to_categorical(y, num_classes):\n",
    "    \"\"\" 1-hot encodes a tensor \"\"\"\n",
    "    new_y = torch.eye(num_classes)[y.cpu().data.numpy(),]\n",
    "    if (y.is_cuda):\n",
    "        return new_y.cuda()\n",
    "    return new_y\n",
    "\n",
    "def show_example(x, y, x_reconstruction, y_pred,save_dir, figname):\n",
    "    x = x.squeeze().cpu().data.numpy()\n",
    "    x = x.permute(0,2,1)\n",
    "    y = y.cpu().data.numpy()\n",
    "    x_reconstruction = x_reconstruction.squeeze().cpu().data.numpy()\n",
    "    _, y_pred = torch.max(y_pred, -1)\n",
    "    y_pred = y_pred.cpu().data.numpy()\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2)\n",
    "    ax[0].imshow(x, cmap='Greys')\n",
    "    ax[0].set_title('Input: %d' % y)\n",
    "    ax[1].imshow(x_reconstruction, cmap='Greys')\n",
    "    ax[1].set_title('Output: %d' % y_pred)\n",
    "    plt.savefig(save_dir + figname + '.png')\n",
    "\n",
    "def save_checkpoint(epoch, train_accuracy, test_accuracy, model, optimizer, path):\n",
    "    savepath  = path + '/checkpoint-%f-%04d.pth' % (test_accuracy, epoch)\n",
    "    state = {\n",
    "        'epoch': epoch,\n",
    "        'train_accuracy': train_accuracy,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }\n",
    "    torch.save(state, savepath)\n",
    "\n",
    "def test(model, loader):\n",
    "    metrics = defaultdict(lambda:list())\n",
    "    hist_acc = []\n",
    "    for batch_id, (x, y) in tqdm(enumerate(loader), total=len(loader),smoothing=0.9):\n",
    "        x = x.float().cuda()\n",
    "        y = y.long().cuda()\n",
    "        x = x.permute(0,2,1)\n",
    "        y_pred,_ = model(x)\n",
    "        # show_example(x, y, x, y_pred, './images', \"fig\")\n",
    "        _, y_pred = torch.max(y_pred, -1)\n",
    "        pred_choice = y_pred.data.max(1)[1]\n",
    "        correct = pred_choice.eq(y.data).cpu().sum()\n",
    "        metrics['accuracy'].append(correct.data)\n",
    "        \n",
    "    hist_acc.append(np.mean(metrics['accuracy']))\n",
    "    metrics['accuracy'] = np.mean(metrics['accuracy'])\n",
    "    return metrics, hist_acc\n",
    "\n",
    "def compute_iou(pred,target,iou_tabel=None):\n",
    "    ious = []\n",
    "    target = target.cpu().data.numpy()\n",
    "    for j in range(pred.size(0)):\n",
    "        batch_pred = pred[j]\n",
    "        batch_target = target[j]\n",
    "        batch_choice = batch_pred.data.max(1)[1].cpu().data.numpy()\n",
    "        for cat in np.unique(batch_target):\n",
    "            intersection = np.sum((batch_target == cat) & (batch_choice == cat))\n",
    "            union = float(np.sum((batch_target == cat) | (batch_choice == cat)))\n",
    "            iou = intersection/union\n",
    "            ious.append(iou)\n",
    "            iou_tabel[cat,0] += iou\n",
    "            iou_tabel[cat,1] += 1\n",
    "    return np.mean(ious), iou_tabel\n",
    "\n",
    "def test_seg(model, loader, catdict, num_classes = 13):\n",
    "    ''' catdict = {0:Airplane, 1:Airplane, ...49:Table} '''\n",
    "    iou_tabel = np.zeros((len(catdict),3))\n",
    "    metrics = defaultdict(lambda:list())\n",
    "    hist_acc = []\n",
    "    for batch_id, (points, target) in tqdm(enumerate(loader), total=len(loader), smoothing=0.9):\n",
    "        batchsize, num_point, _ = points.size()\n",
    "        points, target = Variable(points.float()), Variable(target.long())\n",
    "        points = points.transpose(2, 1)\n",
    "        points, target = points.cuda(), target.cuda()\n",
    "        pred = model(points[:,:3,:],points[:,3:,:])\n",
    "        mean_iou, iou_tabel = compute_iou(pred,target,iou_tabel)\n",
    "        # print(points[:,:3,:])\n",
    "        pred = pred.contiguous().view(-1, num_classes)\n",
    "        target = target.view(-1, 1)[:, 0]\n",
    "        pred_choice = pred.data.max(1)[1]\n",
    "        correct = pred_choice.eq(target.data).cpu().sum()\n",
    "        metrics['accuracy'].append(correct.item()/ (batchsize * num_point))\n",
    "        metrics['iou'].append(mean_iou)\n",
    "    iou_tabel[:,2] = iou_tabel[:,0] /(iou_tabel[:,1]+0.01)\n",
    "    hist_acc += metrics['accuracy']\n",
    "    metrics['accuracy'] = np.mean(metrics['accuracy'])\n",
    "    iou_tabel = pd.DataFrame(iou_tabel,columns=['iou','count','mean_iou'])\n",
    "    iou_tabel['Category_IOU'] = [cat_value for cat_value in catdict.values()]\n",
    "    cat_iou = iou_tabel.groupby('Category_IOU')['mean_iou'].mean()\n",
    "\n",
    "    return metrics, hist_acc, cat_iou\n",
    "\n",
    "def compute_avg_curve(y, n_points_avg):\n",
    "    avg_kernel = np.ones((n_points_avg,)) / n_points_avg\n",
    "    rolling_mean = np.convolve(y, avg_kernel, mode='valid')\n",
    "    return rolling_mean\n",
    "\n",
    "def plot_loss_curve(history,n_points_avg,n_points_plot,save_dir):\n",
    "    curve = np.asarray(history['loss'])[-n_points_plot:]\n",
    "    avg_curve = compute_avg_curve(curve, n_points_avg)\n",
    "    plt.plot(avg_curve, '-g')\n",
    "\n",
    "    curve = np.asarray(history['margin_loss'])[-n_points_plot:]\n",
    "    avg_curve = compute_avg_curve(curve, n_points_avg)\n",
    "    plt.plot(avg_curve, '-b')\n",
    "\n",
    "    curve = np.asarray(history['reconstruction_loss'])[-n_points_plot:]\n",
    "    avg_curve = compute_avg_curve(curve, n_points_avg)\n",
    "    plt.plot(avg_curve, '-r')\n",
    "\n",
    "    plt.legend(['Total Loss', 'Margin Loss', 'Reconstruction Loss'])\n",
    "    plt.savefig(save_dir + '/'+ str(datetime.datetime.now().strftime('%Y-%m-%d %H-%M')) + '_total_result.png')\n",
    "    plt.close()\n",
    "\n",
    "def plot_acc_curve(total_train_acc,total_test_acc,save_dir):\n",
    "    plt.plot(total_train_acc, '-b',label = 'train_acc')\n",
    "    plt.plot(total_test_acc, '-r',label = 'test_acc')\n",
    "    plt.legend()\n",
    "    plt.ylabel('acc')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.title('Accuracy of training and test')\n",
    "    plt.savefig(save_dir +'/'+ str(datetime.datetime.now().strftime('%Y-%m-%d %H-%M'))+'_total_acc.png')\n",
    "    plt.close()\n",
    "\n",
    "def show_point_cloud(tuple,seg_label=[],title=None):\n",
    "    import matplotlib.pyplot as plt\n",
    "    if seg_label == []:\n",
    "        x = [x[0] for x in tuple]\n",
    "        y = [y[1] for y in tuple]\n",
    "        z = [z[2] for z in tuple]\n",
    "        ax = plt.subplot(111, projection='3d')\n",
    "        ax.scatter(x, y, z, c='b', cmap='spectral')\n",
    "        ax.set_zlabel('Z')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.set_xlabel('X')\n",
    "    else:\n",
    "        category = list(np.unique(seg_label))\n",
    "        color = ['b','r','g','y','w','b','p']\n",
    "        ax = plt.subplot(111, projection='3d')\n",
    "        for categ_index in range(len(category)):\n",
    "            tuple_seg = tuple[seg_label == category[categ_index]]\n",
    "            x = [x[0] for x in tuple_seg]\n",
    "            y = [y[1] for y in tuple_seg]\n",
    "            z = [z[2] for z in tuple_seg]\n",
    "            ax.scatter(x, y, z, c=color[categ_index], cmap='spectral')\n",
    "        ax.set_zlabel('Z')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.set_xlabel('X')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "3bKXKEUlGlOW",
    "outputId": "af943ae5-e267-47aa-ba21-a37d2ab93035"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "\n",
    "experiment_dir = Path('./experiment/')\n",
    "print(experiment_dir)\n",
    "experiment_dir.mkdir(exist_ok=True)\n",
    "file_dir = Path(str(experiment_dir) +'/'+ str(datetime.datetime.now().strftime('%Y-%m-%d_%H-%M')))\n",
    "file_dir.mkdir(exist_ok=True)\n",
    "checkpoints_dir = file_dir.joinpath('./checkpoints/')\n",
    "checkpoints_dir.mkdir(exist_ok=True)\n",
    "log_dir = file_dir.joinpath('./logs/')\n",
    "log_dir.mkdir(exist_ok=True)\n",
    "\n",
    "logger = logging.getLogger('GACNet')\n",
    "logger.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "file_handler = logging.FileHandler(str('./logs/') + '/train_GACNet.txt')\n",
    "file_handler.setLevel(logging.INFO)\n",
    "file_handler.setFormatter(formatter)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "# model.cuda()\n",
    "# model.load_state_dict(torch.load('./experiment/2023-05-20_22-47/checkpoints/GACNet_000_0.7575.pth'))\n",
    "\n",
    "seg_classes = class2label\n",
    "seg_label_to_cat = {}\n",
    "for i,cat in enumerate(seg_classes.keys()):\n",
    "    seg_label_to_cat[i] = cat\n",
    "\n",
    "for epoch in range(init_epoch,2):\n",
    "    for i, data in tqdm(enumerate(dataloader, 0),total=len(dataloader),smoothing=0.9):\n",
    "        points, target = data\n",
    "        points, target = Variable(points.float()), Variable(target.long())\n",
    "        points = points.transpose(2, 1)\n",
    "        points, target = points.cuda(), target.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        model = model.train()\n",
    "        pred = model(points[:,:3,:],points[:,3:,:])\n",
    "        pred = pred.contiguous().view(-1, num_classes)\n",
    "        target = target.view(-1, 1)[:, 0]\n",
    "        loss = F.nll_loss(pred, target)\n",
    "        history['loss'].append(loss.cpu().data.numpy())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        step += 1\n",
    "        adjust_learning_rate(optimizer, step)\n",
    "    \n",
    "    test_metrics, test_hist_acc, cat_mean_iou = test_seg(model, testdataloader, seg_label_to_cat)\n",
    "    mean_iou = np.mean(cat_mean_iou)\n",
    "\n",
    "    print('Epoch %d  %s accuracy: %f  meanIOU: %f' % (\n",
    "              epoch, blue('test'), test_metrics['accuracy'],mean_iou))\n",
    "    logger.info('Epoch %d  %s accuracy: %f  meanIOU: %f' % (\n",
    "              epoch, 'test', test_metrics['accuracy'],mean_iou))\n",
    "    if test_metrics['accuracy'] > best_acc:\n",
    "        best_acc = test_metrics['accuracy']\n",
    "        torch.save(model.state_dict(), '%s/GACNet_%.3d_%.4f.pth' % (checkpoints_dir, epoch, best_acc))\n",
    "        logger.info(cat_mean_iou)\n",
    "        logger.info('Save model..')\n",
    "        print('Save model..')\n",
    "        print(cat_mean_iou)\n",
    "    if mean_iou > best_meaniou:\n",
    "        best_meaniou = mean_iou\n",
    "    print('Best accuracy is: %.5f'%best_acc)\n",
    "    logger.info('Best accuracy is: %.5f'%best_acc)\n",
    "    print('Best meanIOU is: %.5f'%best_meaniou)\n",
    "    logger.info('Best meanIOU is: %.5f'%best_meaniou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
